{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW :\n",
    "- Load Data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "df = pd.read_csv('ionosphere_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the shape of the dataset \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear from the shape of the data that dataset is not a huge one. Only 351 records are available with 34 features/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature3</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>0.87111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature4</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.01631</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature5</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>0.80920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature6</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature7</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>0.72873</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature8</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature9</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>0.68421</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature10</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.01829</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature11</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>0.66798</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature12</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.155040</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.065265</td>\n",
       "      <td>0.02825</td>\n",
       "      <td>0.482375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature13</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.400801</td>\n",
       "      <td>0.622186</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.64407</td>\n",
       "      <td>0.955505</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature14</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.073725</td>\n",
       "      <td>0.03027</td>\n",
       "      <td>0.374860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature15</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.344159</td>\n",
       "      <td>0.652828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60194</td>\n",
       "      <td>0.919330</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature16</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.071132</td>\n",
       "      <td>0.458371</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.081705</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.308975</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature17</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.381949</td>\n",
       "      <td>0.618020</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.59091</td>\n",
       "      <td>0.935705</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature18</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>0.496762</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.225690</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.195285</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature19</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.359390</td>\n",
       "      <td>0.626267</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57619</td>\n",
       "      <td>0.899265</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature20</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.024025</td>\n",
       "      <td>0.519076</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.234670</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.134370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature21</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.336695</td>\n",
       "      <td>0.609828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49909</td>\n",
       "      <td>0.894865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature22</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.518166</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.243870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.188760</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature23</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.362475</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.53176</td>\n",
       "      <td>0.911235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature24</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.057406</td>\n",
       "      <td>0.527456</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.366885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature25</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.55389</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature26</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>-0.01505</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature27</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>0.70824</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature28</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>-0.01769</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature29</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49664</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature30</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature31</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.44277</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature32</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature33</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40956</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature34</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.468337</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.165350</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std  min       25%      50%       75%  max\n",
       "feature1   351.0  0.891738  0.311155  0.0  1.000000  1.00000  1.000000  1.0\n",
       "feature2   351.0  0.000000  0.000000  0.0  0.000000  0.00000  0.000000  0.0\n",
       "feature3   351.0  0.641342  0.497708 -1.0  0.472135  0.87111  1.000000  1.0\n",
       "feature4   351.0  0.044372  0.441435 -1.0 -0.064735  0.01631  0.194185  1.0\n",
       "feature5   351.0  0.601068  0.519862 -1.0  0.412660  0.80920  1.000000  1.0\n",
       "feature6   351.0  0.115889  0.460810 -1.0 -0.024795  0.02280  0.334655  1.0\n",
       "feature7   351.0  0.550095  0.492654 -1.0  0.211310  0.72873  0.969240  1.0\n",
       "feature8   351.0  0.119360  0.520750 -1.0 -0.054840  0.01471  0.445675  1.0\n",
       "feature9   351.0  0.511848  0.507066 -1.0  0.087110  0.68421  0.953240  1.0\n",
       "feature10  351.0  0.181345  0.483851 -1.0 -0.048075  0.01829  0.534195  1.0\n",
       "feature11  351.0  0.476183  0.563496 -1.0  0.021120  0.66798  0.957895  1.0\n",
       "feature12  351.0  0.155040  0.494817 -1.0 -0.065265  0.02825  0.482375  1.0\n",
       "feature13  351.0  0.400801  0.622186 -1.0  0.000000  0.64407  0.955505  1.0\n",
       "feature14  351.0  0.093414  0.494873 -1.0 -0.073725  0.03027  0.374860  1.0\n",
       "feature15  351.0  0.344159  0.652828 -1.0  0.000000  0.60194  0.919330  1.0\n",
       "feature16  351.0  0.071132  0.458371 -1.0 -0.081705  0.00000  0.308975  1.0\n",
       "feature17  351.0  0.381949  0.618020 -1.0  0.000000  0.59091  0.935705  1.0\n",
       "feature18  351.0 -0.003617  0.496762 -1.0 -0.225690  0.00000  0.195285  1.0\n",
       "feature19  351.0  0.359390  0.626267 -1.0  0.000000  0.57619  0.899265  1.0\n",
       "feature20  351.0 -0.024025  0.519076 -1.0 -0.234670  0.00000  0.134370  1.0\n",
       "feature21  351.0  0.336695  0.609828 -1.0  0.000000  0.49909  0.894865  1.0\n",
       "feature22  351.0  0.008296  0.518166 -1.0 -0.243870  0.00000  0.188760  1.0\n",
       "feature23  351.0  0.362475  0.603767 -1.0  0.000000  0.53176  0.911235  1.0\n",
       "feature24  351.0 -0.057406  0.527456 -1.0 -0.366885  0.00000  0.164630  1.0\n",
       "feature25  351.0  0.396135  0.578451 -1.0  0.000000  0.55389  0.905240  1.0\n",
       "feature26  351.0 -0.071187  0.508495 -1.0 -0.332390 -0.01505  0.156765  1.0\n",
       "feature27  351.0  0.541641  0.516205 -1.0  0.286435  0.70824  0.999945  1.0\n",
       "feature28  351.0 -0.069538  0.550025 -1.0 -0.443165 -0.01769  0.153535  1.0\n",
       "feature29  351.0  0.378445  0.575886 -1.0  0.000000  0.49664  0.883465  1.0\n",
       "feature30  351.0 -0.027907  0.507974 -1.0 -0.236885  0.00000  0.154075  1.0\n",
       "feature31  351.0  0.352514  0.571483 -1.0  0.000000  0.44277  0.857620  1.0\n",
       "feature32  351.0 -0.003794  0.513574 -1.0 -0.242595  0.00000  0.200120  1.0\n",
       "feature33  351.0  0.349364  0.522663 -1.0  0.000000  0.40956  0.813765  1.0\n",
       "feature34  351.0  0.014480  0.468337 -1.0 -0.165350  0.00000  0.171660  1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1\n",
      "2\n",
      "feature2\n",
      "1\n",
      "feature3\n",
      "219\n",
      "feature4\n",
      "269\n",
      "feature5\n",
      "204\n",
      "feature6\n",
      "259\n",
      "feature7\n",
      "231\n",
      "feature8\n",
      "260\n",
      "feature9\n",
      "244\n",
      "feature10\n",
      "267\n",
      "feature11\n",
      "246\n",
      "feature12\n",
      "269\n",
      "feature13\n",
      "238\n",
      "feature14\n",
      "266\n",
      "feature15\n",
      "234\n",
      "feature16\n",
      "270\n",
      "feature17\n",
      "254\n",
      "feature18\n",
      "280\n",
      "feature19\n",
      "254\n",
      "feature20\n",
      "266\n",
      "feature21\n",
      "248\n",
      "feature22\n",
      "265\n",
      "feature23\n",
      "248\n",
      "feature24\n",
      "264\n",
      "feature25\n",
      "256\n",
      "feature26\n",
      "273\n",
      "feature27\n",
      "256\n",
      "feature28\n",
      "281\n",
      "feature29\n",
      "244\n",
      "feature30\n",
      "266\n",
      "feature31\n",
      "243\n",
      "feature32\n",
      "263\n",
      "feature33\n",
      "245\n",
      "feature34\n",
      "263\n",
      "label\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for feature in df:\n",
    "    print(feature)\n",
    "    print(len(df[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['feature2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[1], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "0         1   0.99539  -0.05889   0.85243   0.02306   0.83398  -0.37708   \n",
       "1         1   1.00000  -0.18829   0.93035  -0.36156  -0.10868  -0.93597   \n",
       "2         1   1.00000  -0.03365   1.00000   0.00485   1.00000  -0.12062   \n",
       "3         1   1.00000  -0.45161   1.00000   1.00000   0.71216  -1.00000   \n",
       "4         1   1.00000  -0.02401   0.94140   0.06531   0.92106  -0.23255   \n",
       "\n",
       "   feature9  feature10  feature11  ...  feature26  feature27  feature28  \\\n",
       "0   1.00000    0.03760    0.85243  ...   -0.51171    0.41078   -0.46168   \n",
       "1   1.00000   -0.04549    0.50874  ...   -0.26569   -0.20468   -0.18401   \n",
       "2   0.88965    0.01198    0.73082  ...   -0.40220    0.58984   -0.22145   \n",
       "3   0.00000    0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4   0.77152   -0.16399    0.52798  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 34 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature1   351 non-null    int64  \n",
      " 1   feature3   351 non-null    float64\n",
      " 2   feature4   351 non-null    float64\n",
      " 3   feature5   351 non-null    float64\n",
      " 4   feature6   351 non-null    float64\n",
      " 5   feature7   351 non-null    float64\n",
      " 6   feature8   351 non-null    float64\n",
      " 7   feature9   351 non-null    float64\n",
      " 8   feature10  351 non-null    float64\n",
      " 9   feature11  351 non-null    float64\n",
      " 10  feature12  351 non-null    float64\n",
      " 11  feature13  351 non-null    float64\n",
      " 12  feature14  351 non-null    float64\n",
      " 13  feature15  351 non-null    float64\n",
      " 14  feature16  351 non-null    float64\n",
      " 15  feature17  351 non-null    float64\n",
      " 16  feature18  351 non-null    float64\n",
      " 17  feature19  351 non-null    float64\n",
      " 18  feature20  351 non-null    float64\n",
      " 19  feature21  351 non-null    float64\n",
      " 20  feature22  351 non-null    float64\n",
      " 21  feature23  351 non-null    float64\n",
      " 22  feature24  351 non-null    float64\n",
      " 23  feature25  351 non-null    float64\n",
      " 24  feature26  351 non-null    float64\n",
      " 25  feature27  351 non-null    float64\n",
      " 26  feature28  351 non-null    float64\n",
      " 27  feature29  351 non-null    float64\n",
      " 28  feature30  351 non-null    float64\n",
      " 29  feature31  351 non-null    float64\n",
      " 30  feature32  351 non-null    float64\n",
      " 31  feature33  351 non-null    float64\n",
      " 32  feature34  351 non-null    float64\n",
      " 33  label      351 non-null    object \n",
      "dtypes: float64(32), int64(1), object(1)\n",
      "memory usage: 93.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for feature in df:\\n    print(feature)\\n    df[feature].hist()\\n    plt.show()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for feature in df:\n",
    "    print(feature)\n",
    "    df[feature].hist()\n",
    "    plt.show()'''\n",
    "\n",
    "# df.hist()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.667980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1    feature3    feature4    feature5    feature6    feature7  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.641342    0.044372    0.601068    0.115889    0.550095   \n",
       "std      0.311155    0.497708    0.441435    0.519862    0.460810    0.492654   \n",
       "min      0.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.472135   -0.064735    0.412660   -0.024795    0.211310   \n",
       "50%      1.000000    0.871110    0.016310    0.809200    0.022800    0.728730   \n",
       "75%      1.000000    1.000000    0.194185    1.000000    0.334655    0.969240   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature8    feature9   feature10   feature11  ...   feature25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.119360    0.511848    0.181345    0.476183  ...    0.396135   \n",
       "std      0.520750    0.507066    0.483851    0.563496  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%     -0.054840    0.087110   -0.048075    0.021120  ...    0.000000   \n",
       "50%      0.014710    0.684210    0.018290    0.667980  ...    0.553890   \n",
       "75%      0.445675    0.953240    0.534195    0.957895  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [1 if lbl == 'g' else 0 for lbl in df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.sample(frac= 0.6, random_state=125)\n",
    "test_data = df.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.iloc[:,-1]\n",
    "train_data = train_data.iloc[:,0:-1]\n",
    "test_label = test_data.iloc[:,-1]\n",
    "test_data = test_data.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns= 'label', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.96775</td>\n",
       "      <td>-0.00482</td>\n",
       "      <td>0.96683</td>\n",
       "      <td>-0.00722</td>\n",
       "      <td>0.87980</td>\n",
       "      <td>-0.03923</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98164</td>\n",
       "      <td>0.02003</td>\n",
       "      <td>0.93772</td>\n",
       "      <td>-0.03034</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.05843</td>\n",
       "      <td>0.92774</td>\n",
       "      <td>-0.03464</td>\n",
       "      <td>0.92226</td>\n",
       "      <td>-0.03673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14754</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.04918</td>\n",
       "      <td>0.57377</td>\n",
       "      <td>-0.01639</td>\n",
       "      <td>0.65574</td>\n",
       "      <td>0.01639</td>\n",
       "      <td>0.85246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31148</td>\n",
       "      <td>-0.34426</td>\n",
       "      <td>0.52385</td>\n",
       "      <td>-0.20325</td>\n",
       "      <td>0.32787</td>\n",
       "      <td>-0.03279</td>\n",
       "      <td>0.27869</td>\n",
       "      <td>-0.44262</td>\n",
       "      <td>0.49180</td>\n",
       "      <td>-0.06557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>0.89706</td>\n",
       "      <td>0.38235</td>\n",
       "      <td>0.91176</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.74265</td>\n",
       "      <td>0.67647</td>\n",
       "      <td>0.45588</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>0.19118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.74265</td>\n",
       "      <td>-0.12500</td>\n",
       "      <td>-0.67925</td>\n",
       "      <td>-0.24131</td>\n",
       "      <td>-0.55147</td>\n",
       "      <td>-0.42647</td>\n",
       "      <td>-0.44118</td>\n",
       "      <td>-0.50735</td>\n",
       "      <td>-0.28676</td>\n",
       "      <td>-0.56618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84557</td>\n",
       "      <td>-0.08580</td>\n",
       "      <td>-0.31745</td>\n",
       "      <td>-0.80553</td>\n",
       "      <td>-0.08961</td>\n",
       "      <td>-0.56435</td>\n",
       "      <td>0.80648</td>\n",
       "      <td>0.04576</td>\n",
       "      <td>0.89514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78932</td>\n",
       "      <td>-0.03718</td>\n",
       "      <td>0.70882</td>\n",
       "      <td>-0.25288</td>\n",
       "      <td>0.77884</td>\n",
       "      <td>-0.14109</td>\n",
       "      <td>-0.21354</td>\n",
       "      <td>-0.78170</td>\n",
       "      <td>-0.18494</td>\n",
       "      <td>-0.59867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>-0.99265</td>\n",
       "      <td>0.80882</td>\n",
       "      <td>0.55147</td>\n",
       "      <td>-0.41912</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "270         1   1.00000   0.08013   0.96775  -0.00482   0.96683  -0.00722   \n",
       "116         1   1.00000  -0.14754   1.00000   0.04918   0.57377  -0.01639   \n",
       "135         1   0.89706   0.38235   0.91176   0.37500   0.74265   0.67647   \n",
       "91          1   0.84557  -0.08580  -0.31745  -0.80553  -0.08961  -0.56435   \n",
       "100         1   1.00000  -1.00000   0.00000   0.00000   0.77941  -0.99265   \n",
       "\n",
       "     feature9  feature10  feature11  ...  feature25  feature26  feature27  \\\n",
       "270   0.87980   -0.03923    1.00000  ...    0.98164    0.02003    0.93772   \n",
       "116   0.65574    0.01639    0.85246  ...    0.31148   -0.34426    0.52385   \n",
       "135   0.45588    0.77941    0.19118  ...   -0.74265   -0.12500   -0.67925   \n",
       "91    0.80648    0.04576    0.89514  ...    0.78932   -0.03718    0.70882   \n",
       "100   0.80882    0.55147   -0.41912  ...   -1.00000   -1.00000   -1.00000   \n",
       "\n",
       "     feature28  feature29  feature30  feature31  feature32  feature33  \\\n",
       "270   -0.03034    1.00000   -0.05843    0.92774   -0.03464    0.92226   \n",
       "116   -0.20325    0.32787   -0.03279    0.27869   -0.44262    0.49180   \n",
       "135   -0.24131   -0.55147   -0.42647   -0.44118   -0.50735   -0.28676   \n",
       "91    -0.25288    0.77884   -0.14109   -0.21354   -0.78170   -0.18494   \n",
       "100   -1.00000    1.00000   -1.00000    1.00000   -1.00000    0.00000   \n",
       "\n",
       "     feature34  \n",
       "270   -0.03673  \n",
       "116   -0.06557  \n",
       "135   -0.56618  \n",
       "91    -0.59867  \n",
       "100    0.00000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270    1\n",
       "116    0\n",
       "135    1\n",
       "91     0\n",
       "100    0\n",
       "      ..\n",
       "213    1\n",
       "161    1\n",
       "141    1\n",
       "59     0\n",
       "113    1\n",
       "Name: label, Length: 211, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardized the Input Variables. **Hint**: Centeralized the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shuffle the data if needed.\n",
    "- Split into 60 and 40 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 33)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 33)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = np.array(train_set.as_matrix())\n",
    "#train_label = np.array(pd.DataFrame(train_label).as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(type(train_label))\n",
    "print(type(test_data))\n",
    "print(type(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float32\n",
      "float32\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dtype)\n",
    "print(train_label.dtype)\n",
    "print(test_label.dtype)\n",
    "print(test_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model : 1 hidden layers including 16 unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,  activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               4352      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(optimizer = 'RMSprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the Model with Epochs (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 158 samples, validate on 53 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/75\n",
      "158/158 [==============================] - 1s 3ms/sample - loss: 0.6324 - acc: 0.6266 - val_loss: 0.4957 - val_acc: 0.8491\n",
      "Epoch 2/75\n",
      "158/158 [==============================] - 0s 203us/sample - loss: 0.5471 - acc: 0.7532 - val_loss: 0.4391 - val_acc: 0.8679\n",
      "Epoch 3/75\n",
      "158/158 [==============================] - 0s 152us/sample - loss: 0.5343 - acc: 0.7722 - val_loss: 0.4088 - val_acc: 0.8868\n",
      "Epoch 4/75\n",
      "158/158 [==============================] - 0s 177us/sample - loss: 0.4560 - acc: 0.8228 - val_loss: 0.3724 - val_acc: 0.8868\n",
      "Epoch 5/75\n",
      "158/158 [==============================] - 0s 190us/sample - loss: 0.4264 - acc: 0.8481 - val_loss: 0.3424 - val_acc: 0.9057\n",
      "Epoch 6/75\n",
      "158/158 [==============================] - 0s 177us/sample - loss: 0.4054 - acc: 0.8987 - val_loss: 0.3122 - val_acc: 0.9057\n",
      "Epoch 7/75\n",
      "158/158 [==============================] - 0s 171us/sample - loss: 0.3734 - acc: 0.8861 - val_loss: 0.2872 - val_acc: 0.9245\n",
      "Epoch 8/75\n",
      "158/158 [==============================] - 0s 165us/sample - loss: 0.3405 - acc: 0.8924 - val_loss: 0.2653 - val_acc: 0.9434\n",
      "Epoch 9/75\n",
      "158/158 [==============================] - 0s 215us/sample - loss: 0.3112 - acc: 0.9241 - val_loss: 0.2453 - val_acc: 0.9434\n",
      "Epoch 10/75\n",
      "158/158 [==============================] - 0s 146us/sample - loss: 0.2924 - acc: 0.9051 - val_loss: 0.2282 - val_acc: 0.9623\n",
      "Epoch 11/75\n",
      "158/158 [==============================] - 0s 146us/sample - loss: 0.2590 - acc: 0.9367 - val_loss: 0.2132 - val_acc: 0.9623\n",
      "Epoch 12/75\n",
      "158/158 [==============================] - 0s 171us/sample - loss: 0.2519 - acc: 0.9304 - val_loss: 0.1994 - val_acc: 0.9623\n",
      "Epoch 13/75\n",
      "158/158 [==============================] - 0s 146us/sample - loss: 0.2259 - acc: 0.9241 - val_loss: 0.1911 - val_acc: 0.9623\n",
      "Epoch 14/75\n",
      "158/158 [==============================] - 0s 139us/sample - loss: 0.2094 - acc: 0.9494 - val_loss: 0.1811 - val_acc: 0.9623\n",
      "Epoch 15/75\n",
      "158/158 [==============================] - 0s 240us/sample - loss: 0.2101 - acc: 0.9494 - val_loss: 0.1770 - val_acc: 0.9623\n",
      "Epoch 16/75\n",
      "158/158 [==============================] - 0s 139us/sample - loss: 0.2086 - acc: 0.9430 - val_loss: 0.1676 - val_acc: 0.9623\n",
      "Epoch 17/75\n",
      "158/158 [==============================] - 0s 139us/sample - loss: 0.1709 - acc: 0.9557 - val_loss: 0.1625 - val_acc: 0.9623\n",
      "Epoch 18/75\n",
      "158/158 [==============================] - 0s 139us/sample - loss: 0.1624 - acc: 0.9494 - val_loss: 0.1601 - val_acc: 0.9623\n",
      "Epoch 19/75\n",
      "158/158 [==============================] - 0s 216us/sample - loss: 0.1697 - acc: 0.9620 - val_loss: 0.1539 - val_acc: 0.9623\n",
      "Epoch 20/75\n",
      "158/158 [==============================] - 0s 152us/sample - loss: 0.1894 - acc: 0.9494 - val_loss: 0.1506 - val_acc: 0.9623\n",
      "Epoch 21/75\n",
      "158/158 [==============================] - 0s 158us/sample - loss: 0.1305 - acc: 0.9557 - val_loss: 0.1462 - val_acc: 0.9623\n",
      "Epoch 22/75\n",
      "158/158 [==============================] - 0s 228us/sample - loss: 0.1432 - acc: 0.9620 - val_loss: 0.1469 - val_acc: 0.9623\n",
      "Epoch 23/75\n",
      "158/158 [==============================] - 0s 158us/sample - loss: 0.1222 - acc: 0.9620 - val_loss: 0.1422 - val_acc: 0.9623\n",
      "Epoch 24/75\n",
      "158/158 [==============================] - 0s 139us/sample - loss: 0.1399 - acc: 0.9557 - val_loss: 0.1425 - val_acc: 0.9623\n",
      "Epoch 25/75\n",
      "158/158 [==============================] - 0s 152us/sample - loss: 0.0978 - acc: 0.9747 - val_loss: 0.1437 - val_acc: 0.9623\n",
      "Epoch 26/75\n",
      "158/158 [==============================] - 0s 164us/sample - loss: 0.1077 - acc: 0.9684 - val_loss: 0.1411 - val_acc: 0.9623\n",
      "Epoch 27/75\n",
      "158/158 [==============================] - 0s 146us/sample - loss: 0.1248 - acc: 0.9620 - val_loss: 0.1412 - val_acc: 0.9623\n",
      "Epoch 28/75\n",
      "158/158 [==============================] - 0s 158us/sample - loss: 0.1134 - acc: 0.9684 - val_loss: 0.1402 - val_acc: 0.9623\n",
      "Epoch 29/75\n",
      "158/158 [==============================] - 0s 209us/sample - loss: 0.0947 - acc: 0.9684 - val_loss: 0.1416 - val_acc: 0.9623\n",
      "Epoch 30/75\n",
      "158/158 [==============================] - 0s 190us/sample - loss: 0.0859 - acc: 0.9810 - val_loss: 0.1364 - val_acc: 0.9623\n",
      "Epoch 31/75\n",
      "158/158 [==============================] - 0s 139us/sample - loss: 0.1044 - acc: 0.9810 - val_loss: 0.1333 - val_acc: 0.9623\n",
      "Epoch 32/75\n",
      "158/158 [==============================] - 0s 133us/sample - loss: 0.0909 - acc: 0.9684 - val_loss: 0.1361 - val_acc: 0.9623\n",
      "Epoch 33/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0901 - acc: 0.9620 - val_loss: 0.1416 - val_acc: 0.9434\n",
      "Epoch 34/75\n",
      "158/158 [==============================] - 0s 177us/sample - loss: 0.1044 - acc: 0.9747 - val_loss: 0.1410 - val_acc: 0.9623\n",
      "Epoch 35/75\n",
      "158/158 [==============================] - 0s 120us/sample - loss: 0.0929 - acc: 0.9684 - val_loss: 0.1337 - val_acc: 0.9434\n",
      "Epoch 36/75\n",
      "158/158 [==============================] - 0s 215us/sample - loss: 0.0680 - acc: 0.9810 - val_loss: 0.1348 - val_acc: 0.9623\n",
      "Epoch 37/75\n",
      "158/158 [==============================] - 0s 133us/sample - loss: 0.0877 - acc: 0.9684 - val_loss: 0.1369 - val_acc: 0.9434\n",
      "Epoch 38/75\n",
      "158/158 [==============================] - 0s 211us/sample - loss: 0.0717 - acc: 0.9810 - val_loss: 0.1378 - val_acc: 0.9623\n",
      "Epoch 39/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0765 - acc: 0.9937 - val_loss: 0.1344 - val_acc: 0.9623\n",
      "Epoch 40/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0777 - acc: 0.9747 - val_loss: 0.1470 - val_acc: 0.9623\n",
      "Epoch 41/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0754 - acc: 0.9873 - val_loss: 0.1388 - val_acc: 0.9623\n",
      "Epoch 42/75\n",
      "158/158 [==============================] - 0s 190us/sample - loss: 0.0556 - acc: 0.9937 - val_loss: 0.1464 - val_acc: 0.9623\n",
      "Epoch 43/75\n",
      "158/158 [==============================] - 0s 133us/sample - loss: 0.0579 - acc: 0.9810 - val_loss: 0.1426 - val_acc: 0.9623\n",
      "Epoch 44/75\n",
      "158/158 [==============================] - 0s 120us/sample - loss: 0.0525 - acc: 0.9937 - val_loss: 0.1503 - val_acc: 0.9623\n",
      "Epoch 45/75\n",
      "158/158 [==============================] - 0s 133us/sample - loss: 0.0638 - acc: 0.9810 - val_loss: 0.1516 - val_acc: 0.9623\n",
      "Epoch 46/75\n",
      "158/158 [==============================] - 0s 184us/sample - loss: 0.0636 - acc: 0.9873 - val_loss: 0.1479 - val_acc: 0.9623\n",
      "Epoch 47/75\n",
      "158/158 [==============================] - 0s 120us/sample - loss: 0.0571 - acc: 0.9810 - val_loss: 0.1529 - val_acc: 0.9623\n",
      "Epoch 48/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0536 - acc: 0.9810 - val_loss: 0.1515 - val_acc: 0.9811\n",
      "Epoch 49/75\n",
      "158/158 [==============================] - 0s 215us/sample - loss: 0.0567 - acc: 0.9810 - val_loss: 0.1496 - val_acc: 0.9811\n",
      "Epoch 50/75\n",
      "158/158 [==============================] - 0s 120us/sample - loss: 0.0528 - acc: 0.9810 - val_loss: 0.1597 - val_acc: 0.9811\n",
      "Epoch 51/75\n",
      "158/158 [==============================] - 0s 133us/sample - loss: 0.0391 - acc: 0.9873 - val_loss: 0.1606 - val_acc: 0.9623\n",
      "Epoch 52/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0286 - acc: 0.9937 - val_loss: 0.1597 - val_acc: 0.9623\n",
      "Epoch 53/75\n",
      "158/158 [==============================] - 0s 196us/sample - loss: 0.0428 - acc: 0.9810 - val_loss: 0.1663 - val_acc: 0.9811\n",
      "Epoch 54/75\n",
      "158/158 [==============================] - 0s 177us/sample - loss: 0.0406 - acc: 0.9810 - val_loss: 0.1694 - val_acc: 0.9811\n",
      "Epoch 55/75\n",
      "158/158 [==============================] - 0s 152us/sample - loss: 0.0301 - acc: 0.9937 - val_loss: 0.1633 - val_acc: 0.9623\n",
      "Epoch 56/75\n",
      "158/158 [==============================] - 0s 133us/sample - loss: 0.0392 - acc: 0.9810 - val_loss: 0.1569 - val_acc: 0.9811\n",
      "Epoch 57/75\n",
      "158/158 [==============================] - 0s 177us/sample - loss: 0.0490 - acc: 0.9937 - val_loss: 0.1572 - val_acc: 0.9811\n",
      "Epoch 58/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0321 - acc: 0.9937 - val_loss: 0.1624 - val_acc: 0.9811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0282 - acc: 0.9873 - val_loss: 0.1619 - val_acc: 0.9811\n",
      "Epoch 60/75\n",
      "158/158 [==============================] - 0s 203us/sample - loss: 0.0367 - acc: 0.9873 - val_loss: 0.1614 - val_acc: 0.9811\n",
      "Epoch 61/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 0.1630 - val_acc: 0.9811\n",
      "Epoch 62/75\n",
      "158/158 [==============================] - 0s 133us/sample - loss: 0.0294 - acc: 0.9937 - val_loss: 0.1648 - val_acc: 0.9811\n",
      "Epoch 63/75\n",
      "158/158 [==============================] - 0s 146us/sample - loss: 0.0382 - acc: 0.9937 - val_loss: 0.1671 - val_acc: 0.9811\n",
      "Epoch 64/75\n",
      "158/158 [==============================] - 0s 196us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.1654 - val_acc: 0.9811\n",
      "Epoch 65/75\n",
      "158/158 [==============================] - 0s 139us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9811\n",
      "Epoch 66/75\n",
      "158/158 [==============================] - 0s 139us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.1654 - val_acc: 0.9811\n",
      "Epoch 67/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0274 - acc: 0.9937 - val_loss: 0.1786 - val_acc: 0.9623\n",
      "Epoch 68/75\n",
      "158/158 [==============================] - 0s 196us/sample - loss: 0.0231 - acc: 0.9937 - val_loss: 0.1687 - val_acc: 0.9811\n",
      "Epoch 69/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.1721 - val_acc: 0.9811\n",
      "Epoch 70/75\n",
      "158/158 [==============================] - 0s 120us/sample - loss: 0.0328 - acc: 0.9873 - val_loss: 0.1732 - val_acc: 0.9811\n",
      "Epoch 71/75\n",
      "158/158 [==============================] - 0s 127us/sample - loss: 0.0216 - acc: 0.9937 - val_loss: 0.1746 - val_acc: 0.9811\n",
      "Epoch 72/75\n",
      "158/158 [==============================] - 0s 165us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.1787 - val_acc: 0.9811\n",
      "Epoch 73/75\n",
      "158/158 [==============================] - 0s 133us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.1862 - val_acc: 0.9811\n",
      "Epoch 74/75\n",
      "158/158 [==============================] - 0s 139us/sample - loss: 0.0212 - acc: 0.9937 - val_loss: 0.1879 - val_acc: 0.9811\n",
      "Epoch 75/75\n",
      "158/158 [==============================] - 0s 171us/sample - loss: 0.0132 - acc: 0.9937 - val_loss: 0.1900 - val_acc: 0.9811\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_label, validation_split=0.25, epochs= 75, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(75)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-efc9058b5f2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_acc_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training and validation accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation Step\n",
    "- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 71us/sample - loss: 0.2292 - acc: 0.9357\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22922882713111384, 0.9357143]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\confusion_matrix.py:193: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'confusion_matrix/SparseTensorDenseAdd:0' shape=(2, 2) dtype=int32>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(\n",
    "    test_label, y_pred, num_classes=2, weights=None, dtype=tf.dtypes.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
